{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injection/recovery tests- Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How accurate is `blasé`?  It depends!  The best way to assess accuracy is to test the code on spectra with known line properties.  We therefore create noised-up synthetic spectra with known perturbations to lines and see how close `blase` comes to recovering the ground truth.  This simulation procedure may be referred to as \"injection/recovery tests\"; it is common in many subfields of science as a strategy for quantifying uncertainty.\n",
    "\n",
    "We anticipate that there is some threshold of signal-to-noise-ratio under which the information loss is just too great to overcome, and `blase` will face the impossibility of sorting signal from noise.  The goal of this experiment is to expose those contours, and build an intuition for the failure modes `blasé` can expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from blase.emulator import SparseLogEmulator, ExtrinsicModel, InstrumentalModel\n",
    "import matplotlib.pyplot as plt\n",
    "from gollum.phoenix import PHOENIXSpectrum\n",
    "from gollum.telluric import TelFitSpectrum\n",
    "from blase.utils import doppler_grid\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need data simply for the wavelength coordinates and pixel sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muler.hpf import HPFSpectrum, HPFSpectrumList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://github.com/OttoStruve/muler_example_data/raw/main/HPF/01_A0V_standards/'\n",
    "filename = 'Goldilocks_20210212T072837_v1.0_0037.spectra.fits'\n",
    "#raw_data = HPFSpectrum(file=path+filename, order=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = HPFSpectrumList.read(path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = HPFSpectrumList(raw_data[2:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.sky_subtract().trim_edges().remove_nans().deblaze().stitch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_coordinates = data.wavelength.value\n",
    "bin_edges = data.bin_edges.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_lo = wavelength_coordinates.min()-30.0\n",
    "wl_hi = wavelength_coordinates.max()+30.0\n",
    "wavelength_grid = doppler_grid(wl_lo, wl_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch a Phoenix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gollum.phoenix import PHOENIXGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_RV = 0.0 # Just say zero for simplicity\n",
    "vsini = 15.9 #km/s\n",
    "resolving_power = 55_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_spectrum = PHOENIXSpectrum(teff=5400, logg=4.5, metallicity=0.0, wl_lo=wl_lo, wl_hi=wl_hi)\n",
    "native_spectrum = native_spectrum.divide_by_blackbody()\n",
    "native_spectrum = native_spectrum.normalize()\n",
    "continuum_fit = native_spectrum.fit_continuum(polyorder=5)\n",
    "native_spectrum = native_spectrum.divide(continuum_fit, handle_meta=\"ff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = native_spectrum.rotationally_broaden(vsini)\n",
    "spectrum = spectrum.rv_shift(observed_RV)\n",
    "spectrum = spectrum.instrumental_broaden(resolving_power=resolving_power).resample(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the PHOENIX stellar model with `blase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stellar_emulator = SparseLogEmulator(native_spectrum.wavelength.value, \n",
    "                                     np.log(native_spectrum.flux.value), prominence=0.01, device=device)\n",
    "stellar_emulator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stellar_emulator.optimize(epochs=1000, LR=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_params = stellar_emulator.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extinsic Layer\n",
    "extrinsic_layer = ExtrinsicModel(wavelength_grid, device=device)\n",
    "vsini = torch.tensor(vsini)\n",
    "extrinsic_layer.ln_vsini.data = torch.log(vsini)\n",
    "extrinsic_layer.to(device)\n",
    "\n",
    "## Stellar emulator Layer\n",
    "stellar_emulator = SparseLogEmulator(wavelength_grid, \n",
    "                                     init_state_dict=stellar_emulator.state_dict(), device=device)\n",
    "stellar_emulator.radial_velocity.data = torch.tensor(observed_RV)\n",
    "stellar_emulator.to(device)\n",
    "\n",
    "# Instrument Layer\n",
    "instrumental_model = InstrumentalModel(bin_edges, wavelength_grid, device=device)\n",
    "instrumental_model.to(device)\n",
    "\n",
    "instrumental_model.ln_sigma_angs.data = torch.log(torch.tensor(0.064))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make fake \"synthetic\" data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perturb individual lines by about 9%, with a 3% systematic offset (all lines are deeper than expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_amp_perturbs = np.random.normal(loc=-0.4, scale=0.7, \n",
    "                                size=stellar_emulator.n_lines)\n",
    "amp_perturbs = np.exp(ln_amp_perturbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(amp_perturbs, bins=np.arange(0, 5,0.1));\n",
    "plt.axvline(1, linestyle='dashed', color='k', label='Unchanged')\n",
    "plt.xlabel('Amplitude scale factor'); plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stellar_emulator.load_state_dict(clone_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    stellar_emulator.amplitudes.data += torch.tensor(ln_amp_perturbs).to(device)\n",
    "    super_res_truth = stellar_emulator.forward()\n",
    "    broadened_flux = extrinsic_layer(super_res_truth)\n",
    "    perturbed = instrumental_model.forward(broadened_flux)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    stellar_emulator.load_state_dict(clone_params)\n",
    "    stellar_flux = stellar_emulator.forward()\n",
    "    broadened_flux = extrinsic_layer(stellar_flux)\n",
    "    pristine = instrumental_model.forward(broadened_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise-up the spectra to $S/N\\sim100$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixels = len(data.wavelength)\n",
    "per_pixel_uncertainty = torch.tensor(0.005, device=device, dtype=torch.float64)\n",
    "noise_draw = np.random.normal(loc=0, scale=per_pixel_uncertainty.cpu(), size=n_pixels)\n",
    "synthetic_data = perturbed + torch.tensor(noise_draw, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(data.wavelength, synthetic_data.cpu(), '.', label='Noised-up', color='k', alpha=0.2)\n",
    "plt.step(data.wavelength, pristine.cpu(), label='Pristine', alpha=1, lw=1)\n",
    "plt.step(data.wavelength, perturbed.cpu(), label='Perturbed', alpha=1, lw=1)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = synthetic_data.to(device)\n",
    "\n",
    "data_wavelength = torch.tensor(\n",
    "    wavelength_coordinates.astype(np.float64), device=device, dtype=torch.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learn a semi-empirical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from tqdm import trange\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix certain parameters, allow others to vary\n",
    "As we have seen before, you can fix parameters by \"turning off their gradients\".  We will start by turning off *ALL* gradients.  Then turn on some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in stellar_emulator.state_dict().keys():\n",
    "    stellar_emulator.__getattr__(key).requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stellar_emulator.amplitudes.requires_grad = True\n",
    "#stellar_emulator.lam_centers.requires_grad = False\n",
    "stellar_emulator.radial_velocity.requires_grad = True\n",
    "instrumental_model.ln_sigma_angs.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(\n",
    "    list(filter(lambda p: p.requires_grad, stellar_emulator.parameters()))\n",
    "    + list(filter(lambda p: p.requires_grad, extrinsic_layer.parameters()))\n",
    "    + list(filter(lambda p: p.requires_grad, instrumental_model.parameters())),\n",
    "    0.01,\n",
    "    amsgrad=True,\n",
    ")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need the prior.  For now, let's just apply priors on the amplitudes (almost everything else is fixed).  We need to set the regularization hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stellar_amp_regularization = 5.1\n",
    "stellar_lam_regularization = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ln_amp_perturbs, ln_amp_perturbs**2/stellar_amp_regularization**2, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    stellar_init_amps = copy.deepcopy(stellar_emulator.amplitudes)\n",
    "    stellar_init_lams = copy.deepcopy(stellar_emulator.lam_centers)\n",
    "\n",
    "# Define the prior on the amplitude\n",
    "def ln_prior(stellar_amps):\n",
    "    \"\"\"\n",
    "    Prior for the amplitude vector\n",
    "    \"\"\"\n",
    "    amp_diff1 = stellar_amps - stellar_init_amps\n",
    "    ln_prior1 = 0.5 * torch.sum((amp_diff1 ** 2) / (stellar_amp_regularization ** 2))\n",
    "    \n",
    "    \n",
    "    #lam_diff1 = stellar_init_lams - lam_centers\n",
    "    #ln_prior3 = 0.5 * torch.sum((lam_diff1 ** 2) / (stellar_lam_regularization ** 2))\n",
    "\n",
    "    return ln_prior1#  + ln_prior3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_iter = trange(n_epochs, desc=\"Training\", leave=True)\n",
    "for epoch in t_iter:\n",
    "    stellar_emulator.train()\n",
    "    extrinsic_layer.train()\n",
    "    instrumental_model.train()\n",
    "    \n",
    "    stellar_flux = stellar_emulator.forward()\n",
    "    broadened_flux = extrinsic_layer(stellar_flux)\n",
    "    detector_flux = instrumental_model.forward(broadened_flux)\n",
    "    \n",
    "    loss = loss_fn(detector_flux / per_pixel_uncertainty, data_target / per_pixel_uncertainty)\n",
    "    loss += ln_prior(stellar_emulator.amplitudes)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    t_iter.set_description(\"Training Loss: {:0.8f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot check the transfer-learned joint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "#plt.plot(data.wavelength, synthetic_data, '.', label='Noised-up', color='k', alpha=0.2)\n",
    "plt.step(data.wavelength, pristine.cpu(), label='Pristine', alpha=0.3, lw=1, color='k')\n",
    "plt.step(data.wavelength, perturbed.cpu(), label='Perturbed', alpha=0.7, lw=2)\n",
    "plt.step(data.wavelength, detector_flux.detach().cpu(), label='Retrieved', alpha=0.7, lw=2)\n",
    "\n",
    "#plt.xlim(8500, 8700)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_truth = perturbed.cpu() - detector_flux.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*per_pixel_uncertainty.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=np.arange(-2, 2, 0.1)\n",
    "pdf = norm.pdf(bins, loc=0, scale=100*per_pixel_uncertainty.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residual_truth*100, bins=bins, density=True);\n",
    "plt.yscale('log'); plt.xlabel('Residual (%)', fontsize=12)\n",
    "plt.plot(bins, pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wavelength_coordinates, residual_truth, 'ko', alpha=0.02)\n",
    "plt.axhline(0,)\n",
    "plt.axhline(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieved line strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(clone_params['amplitudes'].cpu()+ln_amp_perturbs, \n",
    "         clone_params['amplitudes'].cpu(), 'ko', alpha=0.2, label='Injected')\n",
    "plt.plot(clone_params['amplitudes'].cpu()+ln_amp_perturbs, \n",
    "         stellar_emulator.amplitudes.detach().cpu(), 'o', label='Recovered')\n",
    "plt.plot([-8, 0], [-8,0], 'k--', label='1:1')\n",
    "plt.xlim(-8, 0);plt.ylim(-8, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
