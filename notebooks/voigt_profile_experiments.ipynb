{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we use Voigt profiles instead of mere Lorentzians\n",
    "\n",
    "How would we code up a Voigt profile?\n",
    "\n",
    "gully  \n",
    "October 11, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('paper', font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from blase.multiorder import MultiOrder\n",
    "from blase.datasets import HPFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks, find_peaks_cwt, peak_prominences, peak_widths\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "data = HPFDataset(\"../../muler_example_data/HPF/01_A0V_standards/Goldilocks_20210517T054403_v1.0_0060.spectra.fits\")\n",
    "model = MultiOrder(device=device, wl_data=data.data_cube[6, :, :])\n",
    "spectrum = model.forward(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the natural log of the flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(model.wl_native, model.flux_native)\n",
    "plt.xlabel('$\\lambda \\;(\\AA)$')\n",
    "plt.ylabel('Flux density')\n",
    "plt.title('High-resolution PHOENIX spectrum at native sampling');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to clone *most* of those lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_flux = gaussian_filter1d(model.flux_native.cpu(), sigma=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks, _ = find_peaks(-smoothed_flux, distance=10, prominence=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(model.wl_native, model.flux_native)\n",
    "plt.plot(model.wl_native, smoothed_flux)\n",
    "plt.scatter(model.wl_native[peaks], smoothed_flux[peaks], marker='o', fc='r',ec='k', zorder=10, s=15,\n",
    "         label='{:} Most Prominent Pseudo-Lines'.format(len(peaks)))\n",
    "plt.xlabel('$\\lambda \\;(\\AA)$')\n",
    "plt.ylabel('Flux Density')\n",
    "plt.title('High-resolution PHOENIX spectrum Gaussian smoothed to ~ HPF resolution')\n",
    "plt.legend();\n",
    "plt.xlim(8660, 8680)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we can probably reconstruct a decent predictive model of the spectrum with \"only\" ~1000 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominence_data = peak_prominences(-smoothed_flux, peaks)\n",
    "width_data = peak_widths(-smoothed_flux, peaks, prominence_data=prominence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominences, left, right = prominence_data\n",
    "widths, width_heights, left_ips, right_ips = width_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's spot-check against real data to ensure that the cloned model resembles reality, even if coarsely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = data.data_cube[6, 5, :]\n",
    "flux = data.data_cube[0, 5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.step(model.wl_native, smoothed_flux, label='PHOENIX model (smoothed)')\n",
    "plt.step(model.wl_native[peaks], smoothed_flux[peaks], 'o', label='Prominent Peaks')\n",
    "plt.step(wl-0.5, flux, label='Minimally Processed HPF Data')\n",
    "plt.xlim(8650, 8770);\n",
    "plt.xlabel('$\\lambda \\;(\\AA)$')\n",
    "plt.ylabel('Flux Density')\n",
    "plt.title('High-resolution PHOENIX spectrum Gaussian smoothed to ~ HPF resolution')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can replicate most of the structure seen in real data, if only the line strengths (and widths) were slightly different.  That's our goal (eventually)!  In the meantime, we need a function that takes in the signal-processed metadata and returns a decent initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorentzian_line(lam_center, width, amplitude, wavelengths):\n",
    "    '''Return a Lorentzian line, given properties'''\n",
    "    return amplitude/3.141592654 * width/(width**2 + (wavelengths - lam_center)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_line(lam_center, width, amplitude, wavelengths):\n",
    "    '''Return a Gaussian line, given properties'''\n",
    "    return amplitude/(width*torch.sqrt(torch.tensor(2*3.14159))) * torch.exp(-0.5*((wavelengths - lam_center) / width)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_centers = model.wl_native[peaks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the FWHM in units of Angstroms: $$\\sigma(Angstroms) = FWHM\\frac{pixels}{1} \\times \\frac{Angstrom}{pixel} \\times \\frac{1}{2.355}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lam = np.diff(model.wl_native.cpu())[peaks]\n",
    "widths_angs = torch.tensor(widths * d_lam / 2.355) * 0.83804203 *0.77116# Experimentally determined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prominence scale factor may not be exactly 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominence_scale_factor = 0.461*0.55736 # Experimentally determined\n",
    "amplitudes = torch.tensor(prominences * prominence_scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output = gaussian_line(lam_centers.unsqueeze(1), \n",
    "                          widths_angs.unsqueeze(1), \n",
    "                          amplitudes.unsqueeze(1), model.wl_native.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output = lorentzian_line(lam_centers.unsqueeze(1), \n",
    "                          widths_angs.unsqueeze(1), \n",
    "                          amplitudes.unsqueeze(1), model.wl_native.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about Voigts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.special import erfc\n",
    "\n",
    "def erfcx_naive(x):\n",
    "    \"\"\"Erfcx based on erfc\"\"\"\n",
    "    return torch.exp(x*x) * erfc(x)\n",
    "\n",
    "try:\n",
    "    from torch.special import erfcx\n",
    "    print('Woohoo! You have a new version of PyTorch')\n",
    "except ImportError:\n",
    "    erfcx = erfcx_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfcx as scipy_erfcx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = torch.arange(-2, 100.0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vals, erfcx(vals), label='PyTorch erfcx', lw=8, alpha=0.5)\n",
    "plt.plot(vals, erfcx_naive(vals), label='PyTorch Naive erfcx', lw=4)\n",
    "plt.plot(vals, scipy_erfcx(vals), label='SciPy erfcx', lw=2, color='k')\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should use PyTorch 1.11 and higher to get better numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import wofz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an=torch.tensor([ 0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. ,10.5, 11. , 11.5, 12. , 12.5, 13. , 13.5])\n",
    "\n",
    "a2n2=torch.tensor([  0.25,   1.  ,   2.25,   4.  ,   6.25,   9.  ,  12.25, 16.  ,  20.25,  25.  ,  30.25,  36.  ,  42.25,  49.  ,56.25,  64.  ,  72.25,  81.  ,  90.25, 100.  , 110.25, 121.  , 132.25, 144.  , 156.25, 169.  , 182.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an = an.unsqueeze(0).unsqueeze(1)\n",
    "a2n2 = a2n2.unsqueeze(0).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ported from exoJAX to PyTorch.  The terms are:\n",
    "\n",
    "$x = \\frac{\\lambda}{\\sqrt(2)\\beta}$\n",
    "\n",
    "$a = \\frac{\\gamma_L}{\\sqrt(2)\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = widths_angs.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_term = model.wl_native.unsqueeze(0) / (math.sqrt(2) * betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_L = 1.5*torch.ones_like(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_term = gamma_L / (math.sqrt(2) * betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_term = x_term.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_term = a_term.unsqueeze(1)\n",
    "a_term.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Tensor of shape (1258, 338624, 27) is too big.\n",
    "\n",
    "We have a few options:\n",
    "\n",
    "- Use a supercomputer/GPU with more RAM\n",
    "- Use minibatches of lines or wavelengths\n",
    "- Use sparse tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_term.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewofz(x,y):\n",
    "    \"\"\"Real part of wofz (Faddeeva) function based on Algorithm 916\n",
    "    \n",
    "    We apply a=0.5 for Algorithm 916.  \n",
    "    Ported from exojax to PyTorch by gully    \n",
    "    \n",
    "    Args:\n",
    "        x: Torch tensor\n",
    "    Must be shape (N_lines x N_wl x  1)\n",
    "        y: Torch tensor\n",
    "    Must be shape (N_lines x 1 x 1)\n",
    "        \n",
    "    Returns:\n",
    "         Torch tensor:\n",
    "         (N_wl x N_lines)\n",
    "    \"\"\"\n",
    "    xy = x*y\n",
    "    exx = torch.exp(-1.0*x*x)\n",
    "    f = exx * (erfcx(y) * torch.cos(2.0*xy) + x*torch.sin(xy)/math.pi*torch.sinc(xy/math.pi))\n",
    "    y2=y**2\n",
    "    Sigma23=torch.sum((torch.exp(-(an+x)**2)+torch.exp(-(an-x)**2))/(a2n2+y2), axis=2)       \n",
    "    Sigma1=exx*(7.78800786e-01/(0.25+y2)+3.67879450e-01/(1.+y2)+1.05399221e-01/(2.25+y2)+1.83156393e-02/(4.+y2)+1.93045416e-03/(6.25+y2)+1.23409802e-04/(9.+y2)+4.78511765e-06/(12.25+y2)+1.12535176e-07/(16.+y2))\n",
    "    f = f + y/math.pi*(-1*torch.cos(2.0*xy)*Sigma1 + 0.5*Sigma23.unsqueeze(1))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewofz(x_term, a_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = torch.arange(-35.0, 35.0, 0.2).unsqueeze(1)\n",
    "vec2 = 1.2*torch.ones_like(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_sc = vec.numpy()\n",
    "vec2_sc = vec2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewofz(vec, vec2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(vec, rewofz(vec, vec2), lw=4, label='PyTorch')\n",
    "plt.step(vec_sc, wofz(vec_sc + 1j*vec2_sc).real, label='SciPy')\n",
    "plt.legend()\n",
    "plt.axvline(np.sqrt(111-vec2[0]**2), color='k', linestyle='dashed')\n",
    "plt.axvline(-1*np.sqrt(111-vec2[0]**2), color='k', linestyle='dashed')\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-4, 1e0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
