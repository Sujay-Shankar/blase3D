{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone precomputed models with SciPy heuristic estimators\n",
    "\n",
    "In this notebook we will clone precomputed models with SciPy-based heuristic estimators such as `find_peaks`, `peak_prominences` and others.  This step should be considered a coarse first pass.\n",
    "\n",
    "gully  \n",
    "April 26, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('paper', font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from blase.multiorder import MultiOrder\n",
    "from blase.datasets import HPFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks, find_peaks_cwt, peak_prominences, peak_widths\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "data = HPFDataset(\"/Users/mag3842/GitHub/muler_example_data/HPF/01_A0V_standards/Goldilocks_20210517T054403_v1.0_0060.spectra.fits\")\n",
    "model = MultiOrder(device=device, wl_data=data.data_cube[6, :, :])\n",
    "spectrum = model.forward(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the natural log of the flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(model.wl_native, model.flux_native)\n",
    "plt.xlabel('$\\lambda \\;(\\AA)$')\n",
    "plt.ylabel('Flux density')\n",
    "plt.title('High-resolution PHOENIX spectrum at native sampling');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to clone *most* of those lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_flux = gaussian_filter1d(model.flux_native.cpu(), sigma=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks, _ = find_peaks(-smoothed_flux, distance=10, prominence=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(model.wl_native, smoothed_flux)\n",
    "plt.scatter(model.wl_native[peaks], smoothed_flux[peaks], marker='o', fc='w',ec='k', zorder=10, s=5,\n",
    "         label='{:} Most Prominent Pseudo-Lines'.format(len(peaks)))\n",
    "plt.xlabel('$\\lambda \\;(\\AA)$')\n",
    "plt.ylabel('Flux Density')\n",
    "plt.title('High-resolution PHOENIX spectrum Gaussian smoothed to ~ HPF resolution')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we can probably reconstruct a decent predictive model of the spectrum with \"only\" ~1000 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominence_data = peak_prominences(-smoothed_flux, peaks)\n",
    "width_data = peak_widths(-smoothed_flux, peaks, prominence_data=prominence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominences, left, right = prominence_data\n",
    "widths, width_heights, left_ips, right_ips = width_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's spot-check against real data to ensure that the cloned model resembles reality, even if coarsely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = data.data_cube[6, 5, :]\n",
    "flux = data.data_cube[0, 5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.step(model.wl_native, smoothed_flux, label='PHOENIX model (smoothed)')\n",
    "plt.step(model.wl_native[peaks], smoothed_flux[peaks], 'o', label='Prominent Peaks')\n",
    "plt.step(wl-0.5, flux, label='Minimally Processed HPF Data')\n",
    "plt.xlim(8650, 8770);\n",
    "plt.xlabel('$\\lambda \\;(\\AA)$')\n",
    "plt.ylabel('Flux Density')\n",
    "plt.title('High-resolution PHOENIX spectrum Gaussian smoothed to ~ HPF resolution')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can replicate most of the structure seen in real data, if only the line strengths (and widths) were slightly different.  That's our goal (eventually)!  In the meantime, we need a function that takes in the signal-processed metadata and returns a decent initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorentzian_line(lam_center, width, amplitude, wavelengths):\n",
    "    '''Return a Lorentzian line, given properties'''\n",
    "    return amplitude/3.141592654 * width/(width**2 + (wavelengths - lam_center)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_line(lam_center, width, amplitude, wavelengths):\n",
    "    '''Return a Gaussian line, given properties'''\n",
    "    return amplitude/(width*torch.sqrt(torch.tensor(2*3.14159))) * torch.exp(-0.5*((wavelengths - lam_center) / width)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_centers = model.wl_native[peaks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the FWHM in units of Angstroms: $$\\sigma(Angstroms) = FWHM\\frac{pixels}{1} \\times \\frac{Angstrom}{pixel} \\times \\frac{1}{2.355}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lam = np.diff(model.wl_native.cpu())[peaks]\n",
    "widths_angs = torch.tensor(widths * d_lam / 2.355) * 0.83804203 *0.77116# Experimentally determined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prominence scale factor may not be exactly 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominence_scale_factor = 0.461*0.55736 # Experimentally determined\n",
    "amplitudes = torch.tensor(prominences * prominence_scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output = gaussian_line(lam_centers.unsqueeze(1), \n",
    "                          widths_angs.unsqueeze(1), \n",
    "                          amplitudes.unsqueeze(1), model.wl_native.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output = lorentzian_line(lam_centers.unsqueeze(1), \n",
    "                          widths_angs.unsqueeze(1), \n",
    "                          amplitudes.unsqueeze(1), model.wl_native.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporarily tilt the cloned model towards the smoothed spectrum and offset for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_factor = 1 - 0.41801511*(model.wl_native-9800)/3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(model.wl_native, net_spectrum * correction_factor, label='Cloned', zorder=10)\n",
    "plt.plot(model.wl_native, smoothed_flux, label='Smoothed Original')\n",
    "plt.xlabel('$\\lambda \\;(\\AA)$')\n",
    "plt.ylabel('Flux Density')\n",
    "plt.title('Cloned Model comparison')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(model.wl_native, net_spectrum * correction_factor -smoothed_flux, label='Cloned - Original')\n",
    "plt.xlabel('$\\lambda \\;(\\AA)$')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Cloned Model comparison')\n",
    "plt.axhline(0, color='k', linestyle='dashed')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!  We have replicated some / most of the variance in the spectrum.  Let's attempt to tune our clone with a few knobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodness_of_fit_metric(params):\n",
    "    prom_scale, width_scale, slope_factor = params\n",
    "    output = lorentzian_line(lam_centers.unsqueeze(1), \n",
    "                          widths_angs.unsqueeze(1)*width_scale, \n",
    "                          amplitudes.unsqueeze(1)*prom_scale, \n",
    "                           model.wl_native.unsqueeze(0))\n",
    "    net_spectrum = 1-output.sum(0)\n",
    "    correction_factor = 1 - slope_factor*(model.wl_native-9800)/3000\n",
    "    residual = net_spectrum * correction_factor - smoothed_flux\n",
    "    return torch.sum(residual**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = minimize(goodness_of_fit_metric, [0.5, 1.0, 0.41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x # array([0.46130227, 0.83804203, 0.41697805])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that trick ever-so-slightly refines our clone, but only marginally so.\n",
    "\n",
    "## Next steps:\n",
    "\n",
    "1. Tune all of the ~1000 spectral lines simultaneously with Gradient Descent\n",
    "\n",
    "2. Refine the lineshapes to include Lorentzian profile through direct Voigt convolution.\n",
    "\n",
    "This last step may require a GPU!  In either case, we'll want to set up a PyTorch class to run the forward model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
